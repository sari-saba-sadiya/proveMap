{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import googlemaps\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import en_core_web_sm\n",
    "#from flashgeotext.geotext import GeoText\n",
    "#spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geotext import GeoText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from geopy.geocoders import Nominatim\n",
    "#from geopy.exc import GeocoderTimedOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import subprocess\n",
    "#import sys\n",
    "#def install(package):\n",
    "#    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install('flashgeotext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subprocess.check_call([sys.executable, \"-m\", \"spacy\",\"download\",\"en_core_web_lg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmapKey = 'AIzaSyBEkIFZO5qzXOZ3SlK3CvPHzKk4YYPVAk0'\n",
    "gmaps = googlemaps.Client(key=gmapKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfaId = '33' # 22,17,16,11,4\n",
    "itemId = 'gty_'+mfaId\n",
    "tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "website = requests.get('http://www.getty.edu/art/collection/objects/'+mfaId)\n",
    "print(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(website.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemId = soup.find_all(\"meta\", {\"name\":\"object_number\"})[0].get('content').replace(\".\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearStr = []\n",
    "yearNum = []\n",
    "for date in soup.find_all(\"section\", {\"id\":\"object-section-provenance\"})[0].find_all(\"div\", {\"class\":\"small-12 medium-3 large-3 columns\"}):\n",
    "    years = re.findall(r\"[0-9]{4}\",date.text)\n",
    "    if len(years) > 0:\n",
    "        yearNum.append(int(years[-1]))\n",
    "        yearStr.append(years[-1])\n",
    "    else:\n",
    "        yearNum.append(np.nan)\n",
    "        yearStr.append('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1981, 1983]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "begin = 0\n",
    "for ii,year in enumerate(yearNum):\n",
    "    if np.isnan(year):\n",
    "        if not begin:\n",
    "            begin = ii\n",
    "    elif begin:\n",
    "        idx.append((begin,ii))\n",
    "        begin = 0\n",
    "if begin != 0:\n",
    "    idx.append((begin,len(yearNume)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in idx:\n",
    "    for ii in range(a,b):\n",
    "        yearNum[ii] = int((yearNum[b] - yearNum[a-1])/(b-a+1)*(ii-a+1))+yearNum[a-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1981, 1983]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1981', '1983']"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map = {v: k for k, v in GeoText.index.countries.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "personStr = []\n",
    "placesStr = []\n",
    "yearStrF = []\n",
    "yearStrO = []\n",
    "prov_data = soup.find_all(\"section\", {\"id\":\"object-section-provenance\"})[0].find_all(\"div\", {\"class\":\"small-12 medium-9 large-9 columns\"})\n",
    "for ii, data in enumerate(prov_data):\n",
    "    cities = []\n",
    "    countries = []\n",
    "    #print(data.text)\n",
    "    for city in GeoText(data.text).cities:\n",
    "        cities.append(city)\n",
    "    for country in list(GeoText(data.text).country_mentions.keys()):\n",
    "        countries.append(country)\n",
    "    if len(countries) == len(cities):\n",
    "        for t in zip(cities,countries):\n",
    "            placesStr.append(t[0]+', '+inv_map[t[1]])\n",
    "            personStr.append(data.text)\n",
    "            yearStrF.append(yearNum[ii])\n",
    "            yearStrO.append(yearStr[ii])\n",
    "    elif len(countries) < len(cities):\n",
    "        for city in cities:\n",
    "            placesStr.append(city)\n",
    "            personStr.append(data.text)\n",
    "            yearStrF.append(yearNum[ii])\n",
    "            yearStrO.append(yearStr[ii])\n",
    "    else:\n",
    "        for country in countries:\n",
    "            placesStr.append(inv_map[country])\n",
    "            personStr.append(data.text)\n",
    "            yearStrF.append(yearNum[ii])\n",
    "            yearStrO.append(yearStr[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amsterdam, netherlands', 'Boston, united kingdom']"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placesStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "places = []\n",
    "addresses = []\n",
    "coordinates = []\n",
    "provs = []\n",
    "yearO = []\n",
    "a = 500\n",
    "prev_add = set()\n",
    "for ii,year in enumerate(yearStrF):\n",
    "    times.append(year)\n",
    "    yearO.append(yearStrO[ii])\n",
    "    place = placesStr[ii]\n",
    "    places.append(place)\n",
    "    geocode_result = gmaps.geocode(place)\n",
    "    addresses.append(re.sub(r',',';',geocode_result[0]['formatted_address']))\n",
    "    ECo,NCo = geocode_result[0]['geometry']['location'].values()\n",
    "    if addresses[-1] in prev_add:\n",
    "        coordinates.append((ECo+randint(-10,10)/a,NCo+randint(-10,10)/a))\n",
    "    else:\n",
    "        coordinates.append((ECo,NCo))\n",
    "    prev_add.add(addresses[-1])\n",
    "    provs.append(personStr[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amsterdam; Netherlands', 'Boston PE21; UK']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../provenance/'+itemId+'.csv', mode='w') as employee_file:\n",
    "    prov_writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    prov_writer.writerow(['index','buyer','year','place','address','N','E','yearStr'])\n",
    "    for ii,(prov,time,place,address,coordinate,year) in enumerate(zip(provs,times,places,addresses,coordinates,yearO)):\n",
    "        prov_writer.writerow([ii,prov,time,place,address,coordinate[0],coordinate[1],year])\n",
    "    prov_writer.writerow([ii+1,'Getty Museum collections',time,'The Getty Museum','The Getty Museum; LA; US','34.07890666552444', '-118.47392373861906',year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#internalHttp = soup.find_all(\"img\", {\"class\":\"disable-click\"})[0]['src']\n",
    "image_url = soup.find_all(\"meta\", {\"name\":\"thumbimage\"})[0].get('content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    artist = soup.find_all(\"meta\", {\"name\":\"maker\"})[0].get('content')\n",
    "except IndexError:\n",
    "    artist = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = []\n",
    "tags.append(soup.find_all(\"meta\", {\"name\":\"culture\"})[0].get('content'))\n",
    "tags.append(soup.find_all(\"meta\", {\"name\":\"object_type\"})[0].get('content'))\n",
    "tags.append(\"Getty Museum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {'disc': soup.find_all(\"meta\", {\"name\":\"description\"})[0].get('content'), \\\n",
    "            'name' : soup.find_all(\"meta\", {\"name\":\"name\"})[0].get('content'), \\\n",
    "            'by': artist, \\\n",
    "            'image_url': image_url,\n",
    "            'yearmade' : soup.find_all(\"meta\", {\"name\":\"date\"})[0].get('content'),\n",
    "            'tags':tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {}\n",
    "#metadata['disc'] = soup.find_all(\"meta\", {\"name\":\"description\"})[0].get('content')\n",
    "metadata['name'] = soup.find_all(\"meta\", {\"name\":\"name\"})[0].get('content')\n",
    "metadata['by'] = artist\n",
    "metadata['image_url'] = image_url\n",
    "metadata['yearmade'] = soup.find_all(\"meta\", {\"name\":\"date\"})[0].get('content')\n",
    "metadata['tags'] = tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../metadata/'+itemId+'.json', 'w') as outfile:  \n",
    "    json.dump(metadata, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'83-GA-264'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninternalHttp = soup.find_all(\"img\", {\"class\":\"disable-click\"})[0][\\'src\\']\\nimage_url = \\'https://collections.mfa.org/\\' + internalHttp\\nr = requests.get(image_url, stream = True)\\nr.raw.decode_content = True\\nwith open(\\'../media/\\'+itemId+\\'.jpg\\', \\'wb\\') as handler:\\n    handler.write(r.raw.read())\\n'"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "internalHttp = soup.find_all(\"img\", {\"class\":\"disable-click\"})[0]['src']\n",
    "image_url = 'https://collections.mfa.org/' + internalHttp\n",
    "r = requests.get(image_url, stream = True)\n",
    "r.raw.decode_content = True\n",
    "with open('../media/'+itemId+'.jpg', 'wb') as handler:\n",
    "    handler.write(r.raw.read())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, Counter, OrderedDict\n",
    "import re\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_path(path):\n",
    "    _ROOT = '/home/sarisadiya/anaconda3/lib/python3.7/site-packages/geotext'\n",
    "    return os.path.join(_ROOT, 'data', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index():\n",
    "    \"\"\"Load information from the data directory\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A namedtuple with three fields: nationalities cities countries\n",
    "    \"\"\"\n",
    "    nationalities = read_table(get_data_path('nationalities.txt'), sep=':')\n",
    "    #print('000000000000')\n",
    "    \n",
    "    # parse http://download.geonames.org/export/dump/countryInfo.txt\n",
    "    countries = read_table(\n",
    "        get_data_path('countryInfo.txt'), usecols=[4, 0], skip=1)\n",
    "    #print('1111111111111')\n",
    "\n",
    "    # parse http://download.geonames.org/export/dump/cities15000.zip\n",
    "    cities = read_table(get_data_path('cities15000.txt'), usecols=[1, 8])\n",
    "    #print('2222222222222222')\n",
    "\n",
    "    # load and apply city patches\n",
    "    city_patches = read_table(get_data_path('citypatches.txt'))\n",
    "    cities.update(city_patches)\n",
    "\n",
    "    Index = namedtuple('Index', 'nationalities cities countries')\n",
    "    return Index(nationalities, cities, countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table(filename, usecols=(0, 1), sep='\\t', comment='#', encoding='utf-8', skip=0):\n",
    "    \"\"\"Parse data files from the data directory\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: string\n",
    "        Full path to file\n",
    "\n",
    "    usecols: list, default [0, 1]\n",
    "        A list of two elements representing the columns to be parsed into a dictionary.\n",
    "        The first element will be used as keys and the second as values. Defaults to\n",
    "        the first two columns of `filename`.\n",
    "\n",
    "    sep : string, default '\\t'\n",
    "        Field delimiter.\n",
    "\n",
    "    comment : str, default '#'\n",
    "        Indicates remainder of line should not be parsed. If found at the beginning of a line,\n",
    "        the line will be ignored altogether. This parameter must be a single character.\n",
    "\n",
    "    encoding : string, default 'utf-8'\n",
    "        Encoding to use for UTF when reading/writing (ex. `utf-8`)\n",
    "\n",
    "    skip: int, default 0\n",
    "        Number of lines to skip at the beginning of the file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary with the same length as the number of lines in `filename`\n",
    "    \"\"\"\n",
    "\n",
    "    with io.open(filename, 'r', encoding=encoding) as f:\n",
    "        # skip initial lines\n",
    "        for _ in range(skip):\n",
    "            next(f)\n",
    "\n",
    "        # filter comment lines\n",
    "        lines = (line for line in f if not line.startswith(comment))\n",
    "\n",
    "        d = dict()\n",
    "        for line in lines:\n",
    "            columns = line.split(sep)\n",
    "            key = columns[usecols[0]].lower()\n",
    "            try:\n",
    "                value = columns[usecols[1]].rstrip('\\n')\n",
    "            except IndexError:\n",
    "                print(columns)\n",
    "            d[key] = value\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = build_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = read_table(get_data_path('cities15000.txt'), usecols=[1, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris\tUS\n",
      "\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "with io.open(get_data_path('citypatches.txt'), 'r', encoding='utf-8') as f:\n",
    "    sep='\\t'\n",
    "    # skip initial lines\n",
    "    for _ in range(0):\n",
    "        next(f)\n",
    "\n",
    "    # filter comment lines\n",
    "    lines = (line for line in f if not line.startswith('#'))\n",
    "\n",
    "    d = dict()\n",
    "    for line in lines:\n",
    "        columns = line.split(sep)\n",
    "        key = columns[0].lower()\n",
    "        if key == 'paris':\n",
    "            print(line)\n",
    "            print('--------------------------')\n",
    "        value = columns[1].rstrip('\\n')\n",
    "        if key not in d.keys():\n",
    "            d[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FR'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['paris']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_regex = r\"[A-ZÀ-Ú]+[a-zà-ú]+[ \\-]?(?:d[a-u].)?(?:[A-ZÀ-Ú]+[a-zà-ú]+)*\"\n",
    "candidates = re.findall(city_regex, 'Paris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Paris']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [candidate.strip() for candidate in candidates]\n",
    "countries = [each for each in candidates if each.lower() in index.countries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Paris']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'paris' in index.countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [each for each in candidates if each.lower() in index.countries]\n",
    "cities = [each for each in candidates if each.lower() in index.cities and each.lower() not in index.countries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Paris']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[each for each in candidates if each.lower() in index.nationalities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[index.countries[country.lower()] for country in countries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[index.cities[city.lower()] for city in cities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'US'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.cities['paris']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.country_mentions = [self.index.countries[country.lower()]\n",
    "                                 for country in self.countries]\n",
    "        self.country_mentions.extend([self.index.cities[city.lower()]\n",
    "                                      for city in self.cities])\n",
    "        self.country_mentions.extend([self.index.nationalities[nationality.lower()]\n",
    "                                      for nationality in self.nationalities])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
